# Learning material is from StatQuest <br>
https://www.youtube.com/watch?v=CqOfi41LfDw
<br> Main Idea pt1. Step One. <br>
- One hidden Layer
- Two nodes (y1, y2)
- All the weights and bias are optimaized

<br> Main Idea pt2. Step Two. <br>
- One hidden layer with two nodes ( a top node and a bottom node)
- b3 is to be optimized by using the chain rule and gradiant descent
- It takes 9 steps to get the optimized b3 = 2.61, the step size is -0.002

<br> Backpropagation pt1. Step Three. <br>
- b3, w3, w4 is to be optimized by using the chain rule and gradiant descent
- codes to be improved
- to define the criteria as for when the gradiant descent should stop optimizing paramaters
